---
title: "Impact of Storm Events on Public Health and Economics"
author: "Hugo van den Berg"
date: "August 21, 2016"
output: 
    html_document:
      toc: yes
    github_document:
      toc: yes
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = file.path(getwd(), '..'))
knitr::opts_chunk$set(echo = TRUE,
                      cache.path = 'cache')
config.base.url <- 'https://github.com/Hugovdberg/StormData/blob/master/'
```

## Synopsis

In this report I aim to identify the impact of storm events on public health
and economics from (a subset of) the [NOAA Storm Database][1], collected
between 1950 and 2011.

## 1. Data Processing

### 1.1 Libraries

For this analysis we used a range of libraries, which are listed below with
their respective version numbers.
Note this block was weaved with the option `message=FALSE` to hide startup
messages.

```{r load_libs, message=FALSE}
# Reading data
library(readr) # v1.0.0

# Munging data
library(magrittr) # v1.5
library(tidyr) # v0.6.0
library(plyr) # v1.8.4
library(dplyr) # v0.5.0
library(lubridate) # v1.5.6
library(stringr) # v1.1.0

# Imputation
library(mice) # v2.25

# Plotting data
library(ggplot2) # v2.1.0
```

### 1.2 Raw data collection

The [NOAA Storm Database][1] is publicly available but for this report make use
of a dedicated subset specially provided for the Coursera course *[Reproducible
Research][2]*.

```{r get_data, cache=TRUE}
data.url <- paste0('https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2F',
                   'StormData.csv.bz2')
data.raw <- file.path('data', 'StormData.csv.bz2')
if (!file.exists(data.raw)) {
    download.file(url = data.url, destfile = data.raw, mode = "wb")
}

data <- read_csv(file = data.raw,
                 col_types = 'dcccdcccdccccdcdccdddddddcdccccddddcc',
                 progress = FALSE)
data.backup <- data
data <- data.backup
```

### 1.3 Cleaning the data

The raw data contains various variables that are not in optimal form to perform
further analyses.

#### Dates

Dates in the original data are scattered over a number of variables, describing
dates in various different timezones.
To create uniform dates, that can be handled consistently, all dates and times
are converted to `POSIXct` objects.

Unfortunately timezones are hard to get right, and the conversion functions
don't support reading the timezone from the inputstring.
Therefore the dataset is split along the `TIME_ZONE` variable, after which for
each split the dates are converted before merging the data back together.

```{r date_convert}
TZ <- read_csv(file.path('data', 'TZ.csv'))
data %<>% inner_join(TZ)
date.data <- split(x = data, f = data$timezone)
for (tz in seq_along(date.data)) {
    date.data[[tz]] %<>%
        separate("BGN_DATE", "BGN_DATE_", sep = " ", extra = "drop", remove = F) %>%
        separate("END_DATE", "END_DATE_", sep = " ", extra = "drop", remove = F) %>%
        mutate(BGN_TIME_ = ifelse(is.na(BGN_TIME),
                                  '0000',
                                  substr(gsub(':', '', BGN_TIME), 1, 4)),
               END_TIME_ = ifelse(is.na(END_TIME),
                                  '0000',
                                  substr(gsub(':', '', END_TIME), 1, 4)),
               begin.date = as.POSIXct(paste(BGN_DATE_, BGN_TIME_),
                                       format = '%m/%d/%Y %H%M',
                                       tz = print(timezone[1])),
               end.date = as.POSIXct(paste(END_DATE_, END_TIME_),
                                     format = '%m/%d/%Y %H%M',
                                     tz = timezone[1])
               ) #%>%
        # select(-BGN_DATE, -BGN_DATE_,
        #        -END_DATE, -END_DATE_,
        #        -BGN_TIME, -BGN_TIME_,
        #        -END_TIME, -END_TIME_)
}
data <- bind_rows(date.data)# %>% select(-TIME_ZONE)
```

#### Event types

The event types contain a lot of misspelled event types.
The [codebook][3] describes a list of all event types in the `EVTYPE` variable
and a mapping to more consistent names, which is stored in 
[EVTYPE.csv][4].
After renaming the event types they are split on the "/"-character into a
major and minor event type, under the assumption that the major event type is
listed first in the `EVTYPE` variable.

```{r evtype_mapping}
evtypes <- read_csv(file.path('data', 'EVTYPE.csv'), col_types = 'cc')
data %<>% 
    mutate(EVTYPE = mapvalues(EVTYPE, 
                              from = evtypes$from, 
                              to = evtypes$to)) %>%
    separate(EVTYPE, into = c("event.type.major", "event.type.minor"), 
             sep = '/', extra = 'merge', fill = "right") %>%
    mutate_at(vars(event.type.major, event.type.minor), funs(as.factor))
```

#### States and regions

The `STATE` variable contains a number of non-standard state codes.
The [codebook][3] describes a list of all state codes and a mapping to
consistent names for the regions in which the event occurred, which is stored
in [STATE.csv][5].

```{r region_mapping}
states <- read_csv(file.path('data', 'STATE.csv'), col_types = 'cc')
data %<>% 
    mutate(
        region = as.factor(mapvalues(STATE,
                                     from = states$from,
                                     to = states$to))
        )
```

#### Latitude and Longitude

The `LATITUDE`, `LONGITUDE`, `LATITUDE_E`, and `LONGITUDE_` variables contain
the respective latitude and longitude of the start and end of the weather
event.
Both are given in hundreths of degrees, and converted to positive values for
the longitudes.
Missing values in the dataset are represented as `0`, these are converted to
`NA`.

```{r lat_lon}
data %<>%
    mutate(begin.latitude = ifelse(LATITUDE, LATITUDE/100, NA),
           begin.longitude = ifelse(LONGITUDE, -LONGITUDE/100, NA),
           end.latitude = ifelse(LATITUDE_E, LATITUDE_E/100, NA),
           end.longitude = ifelse(LONGITUDE_, -LONGITUDE_/100, NA)) %>%
    select(-LATITUDE, -LATITUDE_E, -LONGITUDE, -LONGITUDE_)
```
## 2. Results

[1]: http://www.ncdc.noaa.gov/stormevents/ 
[2]: https://www.coursera.org/learn/reproducible-research
[3]: `r config.base.url`doc/CodeBook.md
[4]: `r config.base.url`data/EVTYPE.csv
[5]: `r config.base.url`data/STATE.csv
